


Autoencoder?


With highly dimensional, complex datasets (e.g. from sensor data like in computer vision), the importance of finding the underlying significant variables increases proportionately. 
Only by encoding the information in fewer dimensions, processing in realtime becomes a reality and at the same time, meaningful variables can be detected out.
	An autoencoder is a neural network that finds the underlying distribution using an encoder-decoder architecture where the output is trained to be equal to the input while the information going through the network is compressed and simplified in an intermediate layer, the so-called bottleneck.
There is a wide range of applications inter alia noise reduction, semantic hashing and image to position mapping. 
(For semantic hashing, documents as well as queries are encoded in a low dimensional semantic space to be searched in that space.)

The benefit of dimensional reduction in image to position mapping is especially useful for advanced tasks as controlling the speed of a racing car on a Carrera track using reinforcement learning, as reinforcement learning is possible in two or three state dimensions but not practically applicable in more than ten.(multiple_cars.png, benchmark.png)(autoencoder_architecture.png, semantic_hashing.png)

Challenge? 
In this very challenge we provide you with images of a racing car on a Carrera track, which we recorded using a still camera above the track. These images are high dimensional vectors, but a one-dimensional manifold underlies this data. 
We challenge you to encode the images - using an Autoencoder - in two or three dimensions and thus to be able to visualize the one-dimensional manifold.

With highly dimensional, complex datasets (e.g. from sensor data like in computer vision), the importance of finding the underlying significant variables increases proportionately. 
Only by encoding the information in fewer dimensions, processing in realtime becomes a reality and at the same time, meaningful variables can be detected out.
	An autoencoder is a neural network that finds the underlying distribution using an encoder-decoder architecture where the output is trained to be equal to the input while the information going through the network is compressed and simplified in an intermediate layer, the so-called bottleneck.
There is a wide range of applications inter alia noise reduction, image to position mapping and semantic hashing. For semantic hashing, documents as well as queries are encoded in a low dimensional semantic space and thus a semantic search is crafted by comparing documents and queries in that space.
	
(autoencoder_architecture.png, semantic_hashing.png)

Challenge?
We set up a camera above a carrera track to record images from an autonomously controlled racing car. These images are high dimensional vectors, but a one-dimensional manifold underlies this data. Using an autoencoder we challenge you to encode the images in two or three dimensions and thus are able to visualize the one-dimensional manifold. 
The benefit of this low dimensional representation is especially useful for advanced tasks as controlling the speed of the racing car using reinforcement learning, as reinforcement learning is possible in two or three state dimensions but not practical applicable in more than ten.
(multiple_cars.png, benchmark.png)

Dataset:
		'images.npy': (2000, 304, 808, 3)
			-> RGB values: [0-255]
		'range_ground_truth.npy': (2000,)
			-> range from starting position following the track: [0-2*pi]

Submission:
	a) preprocessing function
		-> add your preprocessing step to 'evaluate_encoded_data.ipynb'
	b) encoding model (submodel of autoencoder)
		-> encoder = tf.keras.models.Model(inputs=autoencoder.input, 
										   outputs=autoencoder.layers[<num_layer>].output)
		-> encoder.save('models/encoder_model.h5')
		-> encoder.save_weights('models/encoder_weights', save_format='tf')
	
Evaluation:
	A simple random forest (max_depth=5, n_estimators=5) learns mapping from embedding space to the range the car traveled from the startpoint using the ground truth.
	The error of the mapping equals the score.	

Benchmark: 
	track "zero": 0.18 (best possible: ~0.05)

	High lEvel explanation:

Getting Started:
	1. load images
	2. preprocess images
	3. 


